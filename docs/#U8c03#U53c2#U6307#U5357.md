# PM2.5 训练调参指南

本文基于 `My/config/pm25.yaml` 的默认配置，梳理各类超参数的调整思路与注意事项，便于针对显存、收敛速度、预测精度等需求进行优化。

---

## 1. 数据与时间窗口

| 参数 | 默认值 | 调整建议 |
|------|-------|----------|
| `history_len` | 24 | 决定模型一次看到的历史步数。较短（<12）可能难以捕捉日周期；较长会增加显存与训练时间。调整后需确认 DFT 窗口 `S` ≤ `history_len`。|
| `num_pred` | 12 | 预测步数，与业务需求一致。若增大，需要保证训练集覆盖足够的未来窗口，并根据指标重点（MAE/RMSE）观察性能。|
| 数据划分 | 训练/验证/测试 = 6 : 2 : 2 | 切分按时间顺序，避免信息泄漏。若调整比例，需重新学习 `pattern_keys.npy`（DFT）。语义掩码（DTW）可视为先验，也建议在有严格需求时重新计算。|

---

## 2. 批量与优化器

| 参数 | 默认值 | 调整建议 |
|------|-------|----------|
| `batch_size` | 16 | 首选调整对象。增大有利于梯度稳定与速度，但显存消耗几乎线性增加。|
| `learning_rate` | 5e-4 | Adam 的初始学习率。若 loss 降得慢可小幅提高（如 8e-4），若震荡或验证指标上升则降低（如 3e-4）。可配合 `StepLR`/`ReduceLROnPlateau` 等调度。|
| `epochs` | 50 | 观察验证集 loss 变化；若长期下降，可增加；若过拟合明显，可提前停止。配合 `--run-test` 自动评估测试集。|
| AMP | 默认开启 | 混合精度在绝大多数 NVIDIA GPU 上显著降低显存占用，不建议关闭。若遇到兼容问题，可将 `--device` 指定为 `cpu` 或修改脚本。|

---

## 3. 模型结构

| 参数 | 默认值 | 调整建议 |
|------|-------|----------|
| `K` / `d` / `L` | 8 / 8 / 3 | 影响模型容量与显存开销。优先调节 `K`（空间头数）与 `L`（ST 块层数）；`d` 表示单头维度，一般随着 `K` 改动。显存紧张时可减半甚至减至 (4,4,2)。|
| `geo_ratio` | 0.6 | 地理分支的头占比 (0~1)。调大可增强本地依赖建模，调小则给语义分支更多空间。常见取值 0.5~0.7。|
| `S` / `num_patterns` | 6 / 16 | DFT 分支窗口长度与模式数量。增大能捕捉更多延迟模式，但会增加计算量。若训练集缩短或显存紧张，可将 `S` 调为 4。|
| `time_steps_per_day` | 24 | 与数据频率一致（小时级）。若使用其他频率（如 5 分钟），需要同步修改 `PM25DatasetConfig`、TE 编码逻辑。|

---

## 4. 稀疏注意力与显存

| 参数 | 默认值 | 调整建议 |
|------|-------|----------|
| `spatial_chunk_size` | 64 | 控制稠密注意力的分块大小，越小越节省临时显存但计算偏慢。若显存依然不足，可继续降低、甚至改用完全稀疏 K/V（高级改造）。|
| `geo_neighbors_path` / `sem_neighbors_path` | 稀疏邻接索引 | 由 `mask_to_neighbor_indices` 生成，包含 `indices`+`valid`。若要改变邻居数量，可在生成时设置 `max_neighbors`，并重新保存 `.npz`。|
| `geo_mask_path` / `sem_mask_path` | 掩码 | 若更新阈值/距离或重新计算 DTW，需要重新生成掩码；同时更新 `geo_neighbors.npz`、`sem_neighbors.npz`。|

### 显存调节建议
1. 优先调小 `batch_size`。若仍不足，再考虑降低 `K`/`history_len` 或 `geo_ratio`。
2. 合理设置 `max_neighbors`：减少邻居数量可显著降低稀疏注意力的 gather 大小。
3. 保持 AMP；必要时可在训练脚本中引入梯度检查点（checkpointing）以换取显存。

---

## 5. DFT 模式的再学习

| 情况 | 是否需重生 `pattern_keys.npy` |
|------|-------------------------------|
| 更改训练/验证/测试比例 | **是**。`learn_delay_patterns_from_dataset` 默认依据训练段学习延迟模式。|
| 更改 `S` 或 `num_patterns` | **是**。超参改变需重新学习。|
| 仅调 `batch_size` / `epochs` 等优化参数 | 否。|
| 更换目标特征 (`feature_idx`) | 建议重新生成，因目标序列不同。|

命令参考（默认 6 : 2 : 2 划分已执行）：
```bash
python - <<'PY'
from pathlib import Path
from My.utils.patterns import learn_delay_patterns_from_dataset
learn_delay_patterns_from_dataset(
    Path('My/dataset'),
    window=6,
    num_patterns=16,
    stride=6,
    normalize=True,
    cache_path=Path('My/artifacts/pattern_keys.npy'),
)
PY
```

---

## 6. 目标 / 评估指标

当前指标函数位于 `My/utils/metrics.py`（MAE、RMSE、RSE）。保持与 GMAN_PDFusion 相同的输出形状 `[B, Q, N]`，即可复用 `train_pm25.py` / `test_pm25.py` / `evaluate.py` 进行对比。若引入新指标，请确保在训练脚本和日志中同步输出。

---

## 7. 调参流程建议

1. **确定业务需求**：窗口长度、预测步数、训练划分。
2. **预处理**：重新生成必要的产物（`pattern_keys.npy`、掩码等）。
3. **内存压力测试**：先用较小 `batch_size` + `--max-train-steps` 跑通，观察 `nvidia-smi`。
4. **LR & 批量调整**：在显存允许范围内增大 `batch_size`，配合 `learning_rate` 调整学习稳定性。
5. **模型容量微调**：根据验证集表现加减 `K` / `L` / `geo_ratio`，或调整 DFT 相关超参。
6. **最终训练**：全量训练 + `--run-test`，记录日志与 checkpoint。

---

## 8. 参考命令

训练（GPU + 混合精度 + 结束后自动测试）：
```bash
python My/scripts/train_pm25.py \
  --config My/config/pm25.yaml \
  --device cuda \
  --run-test
```

测试（单独评估最佳 checkpoint）：
```bash
python My/scripts/test_pm25.py \
  --config My/config/pm25.yaml \
  --checkpoint My/results/runs/<timestamp>/best_model.pt \
  --device cuda
```

快速对比（占位模型）：
```bash
python My/scripts/evaluate.py \
  --config My/config/pm25.yaml \
  --models GMAN_PDFusion,MLP,GCN \
  --max-batches 5
```

---

如需进一步扩展（引入 GCN/STGCN/Informer 等），建议复用以上数据契约和训练脚手架，将超参调整思路应用到新的模型结构上。***
